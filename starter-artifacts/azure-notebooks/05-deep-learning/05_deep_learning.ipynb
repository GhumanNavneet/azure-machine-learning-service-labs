{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 1 - Train an autoencoder using GPU #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras.utils.vis_utils import plot_model\nimport azureml\nfrom azureml.core import Run\nfrom azureml.core import Workspace\nfrom azureml.core.experiment import Experiment\nimport pickle\n\n# Verify we have a GPU available\n# The output of the following should not be an empty array\n# If you get an empty array back, it means no GPU was detected, which might mean you need to \n# uninstall keras/tensorflow/tensorflow-gpu and then reinstall tensorflow-gpu and keras\nK.tensorflow_backend._get_available_gpus()\n\n# We use Fashion mnist dataset\nfrom keras.datasets import fashion_mnist\n\n# We download and load the data\n(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n\n\n# Build the encoder\ninput_img = Input(shape=(28, 28, 1))\n\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded_feature_vector = MaxPooling2D((2, 2), padding='same', name='feature_vector')(x)\n\n# at this point the representation is (4, 4, 8) i.e. 128-dimensional compressed feature vector\n\n# Build the decoder\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded_feature_vector)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded_output = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\n\n# The first model is autoencoder model, it takes the input image and results in a decoded image\nautoencoder_model = Model(input_img, decoded_output)\n# Compile the first model\nautoencoder_model.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n\n# The second NN model is only a half of the first model, it take the input image and gives the encoded vector as output\nencoder_model = Model(inputs=autoencoder_model.input,\n                                 outputs=autoencoder_model.get_layer('feature_vector').output) # <---- take the output from the feature vector\n# Compile the second model\nencoder_model.compile(optimizer='adadelta', loss='binary_crossentropy')\n\n# We need to scale the image from [0-255] to [0-1] for better performance of activation functions\nx_train = x_train / 255.\nx_test = x_test / 255.\n\n\n# We train the NN in batches (groups of images), so we reshape the dataset\nx_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\nx_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n\nprint(\"Train dataset size is {0}\".format(x_train.shape))\nprint(\"Test dataset size is {0}\".format(x_test.shape))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 2 - Train a neural network #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# It takes several minutes to train this neural network, depending on the configuration of your cluster.\nlearning_history=autoencoder_model.fit(x=x_train, y=x_train, epochs=10, batch_size=128, \n                                 shuffle=True, validation_data=(x_test, x_test), verbose=1)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 3 - Test the model #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "encoded_decoded_image=autoencoder_model.predict(x_test)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 4 - Export and Register the model #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"xxx-xxx-xxx\"\n\n#Provide values for the Resource Group and Workspace that will be created\nresource_group = \"aml-workspace-z\"\nworkspace_name = \"aml-workspace-z\"\nworkspace_region = 'westcentralus' # eastus, westcentralus, southeastasia, australiaeast, westeurope\n\n# By using the exist_ok param, if the worskpace already exists we get a reference to the existing workspace instead of an error\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nprint(\"Workspace Provisioning complete.\")\n\n# Serialize the model to a pickle file in the outputs folder\nmodel_name = 'autoencoder'\nimport os\nos.makedirs('outputs', exist_ok=True)\noutput_model_path = 'outputs/' + model_name + '.pkl'\nautoencoder_model.save(output_model_path)\nprint('Exported model to ', output_model_path)\n# notice for the model_path, we supply the name of the outputs folder without a trailing slash\nregistered_model = azureml.core.model.Model.register(model_path='outputs', model_name=model_name, workspace=ws)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}