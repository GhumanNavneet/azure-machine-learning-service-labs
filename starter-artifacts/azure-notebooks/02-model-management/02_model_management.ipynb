{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 1 - load the training data locally #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model \nfrom sklearn.externals import joblib\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport azureml\nfrom azureml.core import Run\nfrom azureml.core import Workspace\nfrom azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\nimport pickle\n\nprint(\"Current working directory is \", os.path.abspath(os.path.curdir))\ndf_affordability = pd.read_csv('./data/UsedCars_Affordability.csv', delimiter=',')\nprint(df_affordability.head())\n\nfull_X = df_affordability[[\"Age\", \"KM\"]]\nfull_Y = df_affordability[[\"Affordable\"]]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 2 - Define a helper method for training, evaluating and registering#"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "def train_eval_register_model(experiment_name, full_X, full_Y,training_set_percentage):\n\n    # start a training run by defining an experiment\n    myexperiment = Experiment(ws, experiment_name)\n    run = myexperiment.start_logging()\n\n\n    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, train_size=training_set_percentage, \n                                                        random_state=42)\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(train_X)\n    clf = linear_model.LogisticRegression(C=1)\n    clf.fit(X_scaled, train_Y)\n\n    scaled_inputs = scaler.transform(test_X)\n    predictions = clf.predict(scaled_inputs)\n    score = accuracy_score(test_Y, predictions)\n\n    print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n\n    # Log the training metrics to Azure Machine Learning service run history\n    run.log(\"Training_Set_Percentage\", training_set_percentage)\n    run.log(\"Accuracy\", score)\n    run.complete()\n\n    # Save the model to your local outputs directory\n    model_name = experiment_name + '.pkl'\n    output_model_path = './outputs/' + model_name\n    pickle.dump(clf,open(output_model_path,'wb'))\n    \n    # Upload and register this version of the model with Azure Machine Learning service\n    destination_path = 'outputs/' + model_name\n    run.upload_file(destination_path, output_model_path) # destination, source\n    registered_model = run.register_model(model_name='usedcarsmodel', model_path=destination_path)\n\n    print(registered_model.name, registered_model.id, registered_model.version, sep = '\\t')\n\n    return (clf, score)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 3 - Run a few experiments in your Azure ML Workspace #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Verify AML SDK Installed\nprint(\"SDK Version:\", azureml.core.VERSION)\n\n\n# Create a new Workspace or retrieve the existing one\n#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"xxx-xxx-xxx\"\n\n#Provide values for the Resource Group and Workspace that will be created\nresource_group = \"aml-workspace-z\"\nworkspace_name = \"aml-workspace-z\"\nworkspace_region = 'westcentralus' # eastus, westcentralus, southeastasia, australiaeast, westeurope\n\n# By using the exist_ok param, if the worskpace already exists we get a reference to the existing workspace instead of an error\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nprint(\"Workspace Provisioning complete.\")\n\n\n# Create an experiment, log metrics and register the created models for multiple training runs\nexperiment_name = \"Experiment-02-01\"\ntraining_set_percentage = 0.25\nmodel, score = train_eval_register_model(experiment_name, full_X, full_Y, training_set_percentage)\n\nexperiment_name = \"Experiment-02-02\"\ntraining_set_percentage = 0.5\nmodel, score = train_eval_register_model(experiment_name, full_X, full_Y, training_set_percentage)\n\nexperiment_name = \"Experiment-02-03\"\ntraining_set_percentage = 0.75\nmodel, score = train_eval_register_model(experiment_name, full_X, full_Y, training_set_percentage)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 4 - Query for all Experiments #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# You can retreive the list of all experiments in Workspace using the following:\nall_experiments = ws.experiments\n\nprint(all_experiments)\n\n# Query for the metrics of a particular experiment\n# You can retrieve an existing experiment by constructing an Experiment object using the name of an existing experiment.\nmy_experiment = Experiment(ws, \"Experiment-02-03\")\nprint(my_experiment)\n\n# Query an experiment for metrics\n# With an experiment in hand, you retrieve any metrics collected for any of its child runs \nmy_experiment_runs = my_experiment.get_runs()\nprint( [ (run.experiment.name, run.id, run.get_metrics()) for run in my_experiment_runs] )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 5 - Submit an experiment to AML Compute and log metrics for multiple training runs #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "experiment_name = \"UsedCars_Batch_02\"\n\nfrom azureml.core import Experiment\nexp = Experiment(workspace=ws, name=experiment_name)\n\nfrom azureml.core.compute import AmlCompute\nfrom azureml.core.compute import ComputeTarget\nimport os\n\n# choose a name for your cluster\nbatchai_cluster_name = \"carscluster02\"\ncluster_min_nodes = 1\ncluster_max_nodes = 3\nvm_size = \"STANDARD_DS11_V2\"\n\nif batchai_cluster_name in ws.compute_targets:\n    compute_target = ws.compute_targets[batchai_cluster_name]\n    if compute_target and type(compute_target) is AmlCompute:\n        print('Found existing compute target, using this compute target instead of creating:  ' + \n              batchai_cluster_name)\nelse:\n    print('Creating a new compute target...')\n    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,  \n                                                                vm_priority = 'lowpriority', # optional\n                                                                min_nodes = cluster_min_nodes, \n                                                                max_nodes = cluster_max_nodes)\n\n    # create the cluster\n    compute_target = ComputeTarget.create(ws, batchai_cluster_name, provisioning_config)\n    \n    # can poll for a minimum number of nodes and for a specific timeout. \n    # if no min node count is provided it will use the scale settings for the cluster\n    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\n    \n     # For a more detailed view of current BatchAI cluster status, use the 'status' property    \n    print(compute_target.status.serialize())\n\n# Upload the dataset to the DataStore\nds = ws.get_default_datastore()\nprint(ds.datastore_type, ds.account_name, ds.container_name)\nds.upload(src_dir='./data', target_path='used_cars', overwrite=True, show_progress=True)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Prepare batch training script\n# - See ./training/train.py\n\n\n# Create estimator\nfrom azureml.train.estimator import Estimator\n\nscript_params = {\n    '--data-folder': ds.as_mount(),\n    '--training-set-percentage': 0.3\n}\n\nest_config = Estimator(source_directory='./training',\n                script_params=script_params,\n                compute_target=compute_target,\n                entry_script='train.py',\n                conda_packages=['scikit-learn','pandas'])\n\n# Execute the job\nrun = exp.submit(config=est_config)\n\n# Poll for job status\nrun.wait_for_completion(show_output=True) # value of True will display a verbose, streaming log\n\nprint(run.get_file_names())\n\n# Register this version of the model with Azure Machine Learning service\nregistered_model = run.register_model(model_name='usedcarsmodel', model_path='outputs/model.pkl')\n\nprint(registered_model.name, registered_model.id, registered_model.version, sep = '\\t')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 6 - Retrieve the metrics for the model trained in AML Compute #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Examine the recorded metrics from the run\nprint(run.get_metrics())",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}