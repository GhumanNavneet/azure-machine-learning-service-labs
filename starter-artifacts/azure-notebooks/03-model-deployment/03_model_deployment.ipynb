{
  "cells": [
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 1 - Load training data and define model training function #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn import linear_model \nfrom sklearn.externals import joblib\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nimport azureml\nfrom azureml.core import Run\nfrom azureml.core import Workspace\nfrom azureml.core.run import Run\nfrom azureml.core.experiment import Experiment\nfrom azureml.core.model import Model \nimport pickle\nimport json\n\n# Verify AML SDK Installed\n# view version history at https://pypi.org/project/azureml-sdk/#history \nprint(\"SDK Version:\", azureml.core.VERSION)\n\n\n# Load our training data set\nprint(\"Current working directory is \", os.path.abspath(os.path.curdir))\ndf_affordability = pd.read_csv('./data/UsedCars_Affordability.csv', delimiter=',')\nprint(df_affordability.head())\n\nfull_X = df_affordability[[\"Age\", \"KM\"]]\nfull_Y = df_affordability[[\"Affordable\"]]\n\n# Define a helper method that will train, score and register the classifier using different settings\ndef train_eval_register_model(ws, experiment_name, model_name, full_X, full_Y,training_set_percentage):\n\n    # start a training run by defining an experiment\n    myexperiment = Experiment(ws, experiment_name)\n    run = myexperiment.start_logging()\n\n    train_X, test_X, train_Y, test_Y = train_test_split(full_X, full_Y, \n                                                        train_size=training_set_percentage, random_state=42)\n\n    scaler = StandardScaler()\n    X_scaled = scaler.fit_transform(train_X)\n    clf = linear_model.LogisticRegression(C=1)\n    clf.fit(X_scaled, train_Y)\n\n    scaled_inputs = scaler.transform(test_X)\n    predictions = clf.predict(scaled_inputs)\n    score = accuracy_score(test_Y, predictions)\n\n    print(\"With %0.2f percent of data, model accuracy reached %0.4f.\" % (training_set_percentage, score))\n\n    # Log the training metrics to Azure Machine Learning service run history\n    run.log(\"Training_Set_Percentage\", training_set_percentage)\n    run.log(\"Accuracy\", score)\n\n    # Serialize the model to a pickle file in the outputs folder\n    output_model_path = 'outputs/' + model_name + '.pkl'\n    pickle.dump(clf,open(output_model_path,'wb'))\n    print('Exported model to ', output_model_path)\n\n    # Serialize the scaler as a pickle file in the same folder as the model\n    output_scaler_path = 'outputs/' + 'scaler' + '.pkl'\n    pickle.dump(scaler,open(output_scaler_path,'wb'))\n    print('Exported scaler to ', output_scaler_path)\n    \n    # notice for the model_path, we supply the name of the outputs folder without a trailing slash\n    # this will ensure both the model and the scaler get uploaded.\n    registered_model = Model.register(model_path='outputs', model_name=model_name, workspace=ws)\n\n    print(registered_model.name, registered_model.id, registered_model.version, sep = '\\t')\n\n    run.complete()\n\n    return (registered_model, clf, scaler, score, run)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 2 - Retrieve the AML Workspace and Train a model #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "#Provide the Subscription ID of your existing Azure subscription\nsubscription_id = \"xxx-xxx-xxx\"\n\n#Provide values for the Resource Group and Workspace that will be created\nresource_group = \"aml-workspace-z\"\nworkspace_name = \"aml-workspace-z\"\nworkspace_region = 'westcentralus' # eastus, westcentralus, southeastasia, australiaeast, westeurope\n\n# By using the exist_ok param, if the worskpace already exists we get a reference to the existing workspace\nws = Workspace.create(\n    name = workspace_name,\n    subscription_id = subscription_id,\n    resource_group = resource_group, \n    location = workspace_region,\n    exist_ok = True)\n\nprint(\"Workspace Provisioning complete.\")\n\n\n# Create an experiment, log metrics and register the created model\nexperiment_name = \"Experiment-03-30\"\nmodel_name = \"usedcarsmodel\"\ntraining_set_percentage = 0.50\nregistered_model, model, scaler, score, run = train_eval_register_model(ws, experiment_name, \n                                                                        model_name, full_X, full_Y, \n                                                                        training_set_percentage)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 3 - Download the registered model, re-load  the model and verify it still works #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Download the model to a local directory\nmodel_path = Model.get_model_path(model_name, _workspace=ws)\nage = 60\nkm = 40000\n\n# Re-load the model\nscaler = pickle.load(open(os.path.join(model_path,'scaler.pkl'),'rb'))\nscaled_input = scaler.transform([[age, km]])\nmodel2 = pickle.load(open(os.path.join(model_path,'usedcarsmodel.pkl'), 'rb'))\n\n# Use the loaded model to make a prediction\nprediction = model2.predict(scaled_input)\nprint(prediction)\nprediction_json = json.dumps(prediction.tolist())\nprint(prediction_json)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 4 - Create a Conda dependencies environment file #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.conda_dependencies import CondaDependencies \n\nmycondaenv = CondaDependencies.create(conda_packages=['scikit-learn','numpy','pandas'])\n\nwith open(\"mydeployenv.yml\",\"w\") as f:\n    f.write(mycondaenv.serialize_to_string())",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 5 - Create container image configuration #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create the scoring script\n# See the scoring script available in ./score.py\n\n# Build the ContainerImage\nruntime = \"python\" \ndriver_file = \"03-model-deployment-score.py\"\nconda_file = \"mydeployenv.yml\"\n\nfrom azureml.core.image import ContainerImage\n\nimage_config = ContainerImage.image_configuration(execution_script = driver_file,\n                                                  runtime = runtime,\n                                                  conda_file = conda_file)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 6 - Create ACI configuration #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.webservice import AciWebservice, Webservice\n\naci_config = AciWebservice.deploy_configuration(\n    cpu_cores = 1, \n    memory_gb = 1, \n    tags = {'name':'Azure ML ACI'}, \n    description = 'This is a great example.')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 7 -Deploy the webservice to ACI #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "service_name = \"usedcarsmlservice01\"\n\nwebservice = Webservice.deploy_from_model(\n  workspace=ws, \n  name=service_name, \n  deployment_config=aci_config,\n  models = [registered_model], \n  image_config=image_config, \n  )",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 8 - Test the ACI deployed webservice #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\nage = 60\nkm = 40000\ntest_data  = json.dumps([[age,km]])\nprint(test_data)\nwebservice = Webservice(workspace=ws, name=service_name)\n# If the webservice is not ready, run this cell again...\nresult = webservice.run(input_data=test_data)\nprint(result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 9 - Provision an AKS cluster #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "from azureml.core.compute import AksCompute, ComputeTarget\nfrom azureml.core.webservice import Webservice, AksWebservice\n\n# Use the default configuration, overriding the default location to a known region that supports AKS\nprov_config = AksCompute.provisioning_configuration(location='westus2')\n\naks_name = 'aks-cluster01' \n\n# Create the cluster\naks_target = ComputeTarget.create(workspace = ws, \n                                  name = aks_name, \n                                  provisioning_configuration = prov_config)\n\n\n# Wait for cluster to be ready\naks_target.wait_for_completion(show_output = True)\nprint(aks_target.provisioning_state)\nprint(aks_target.provisioning_errors)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 10 - Deploy webservice to AKS #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "# Create the web service configuration (using defaults)\naks_config = AksWebservice.deploy_configuration()\n\naks_service_name ='usedcarsaksservice'\n\naks_service = Webservice.deploy_from_model(\n  workspace=ws, \n  name=aks_service_name, \n  deployment_config=aks_config,\n  models = [registered_model], \n  image_config=image_config,\n  deployment_target=aks_target\n  )\n\n\naks_service.wait_for_deployment(show_output = True)\nprint(aks_service.state)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Step 11 - Test the AKS deployed webservice #"
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "import json\nage = 60\nkm = 40000\ntest_data  = json.dumps([[age,km]])\nprint(test_data)\nresult = aks_service.run(input_data=test_data)\nprint(result)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": false
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}